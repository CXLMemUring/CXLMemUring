#!/usr/bin/env bash
# Compile MCF with profile-guided offload optimizations for heterogeneous execution
#
# Uses:
# - Per-offload-point profile from RTL simulation
# - Dominator tree analysis for H2D/D2H placement
# - Liveness analysis to minimize data transfers
# - Overhead heuristics for offload decisions

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_ROOT="${SCRIPT_DIR}/.."

# Directories
BUILD_DIR="${REPO_ROOT}/build"
BIN_DIR="${REPO_ROOT}/bin"
PROFILE_DIR="${REPO_ROOT}/profile_results"
MCF_SRC="${REPO_ROOT}/bench/mcf"

# Profile files
PER_POINT_PROFILE="${PROFILE_DIR}/per_offload_point_profile.json"
COMPILER_PROFILE="${PROFILE_DIR}/compiler_offload_profile.json"

# Output directories
OUTPUT_DIR="${BIN_DIR}/mcf_heterogeneous"
KERNEL_DIR="${OUTPUT_DIR}/kernels"

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() { echo -e "${GREEN}[INFO]${NC} $*"; }
log_warn() { echo -e "${YELLOW}[WARN]${NC} $*"; }
log_step() { echo -e "${BLUE}[STEP]${NC} $*"; }

mkdir -p "${OUTPUT_DIR}" "${KERNEL_DIR}"

#==============================================================================
# Step 1: Generate offload annotations from profile
#==============================================================================

generate_offload_annotations() {
    log_step "Step 1: Generating offload annotations from per-point profile..."

    python3 << 'EOF'
import json
import os

profile_path = os.environ.get('PER_POINT_PROFILE')
output_dir = os.environ.get('OUTPUT_DIR')

with open(profile_path, 'r') as f:
    profile = json.load(f)

# Generate C header with offload annotations
header = """// Auto-generated offload annotations from profile-guided analysis
// DO NOT EDIT - Generated by compile_mcf_heterogeneous.sh

#ifndef MCF_OFFLOAD_ANNOTATIONS_H
#define MCF_OFFLOAD_ANNOTATIONS_H

// Offload point decisions based on overhead analysis
"""

for point in profile['offload_points']:
    point_id = point['id'].upper()
    decision = point['heuristics']['decision']

    # Generate macros for each offload point
    if decision == 'gpu_always':
        header += f"#define OFFLOAD_{point_id} 1\n"
        header += f"#define {point_id}_MIN_ELEMENTS {point['heuristics'].get('crossover_point_elements', 0)}\n"
    elif decision == 'conditional_offload':
        header += f"#define OFFLOAD_{point_id} 2  // Conditional\n"
        header += f"#define {point_id}_MIN_ELEMENTS {point['heuristics'].get('crossover_point_elements', 0)}\n"
    else:
        header += f"#define OFFLOAD_{point_id} 0  // CPU only\n"
        header += f"#define {point_id}_MIN_ELEMENTS 0\n"

    # H2D/D2H placement hints from dominator analysis
    dom = point['dominator_analysis']
    header += f"#define {point_id}_CAN_HOIST_H2D {1 if dom['can_hoist_h2d'] else 0}\n"
    header += f"#define {point_id}_CAN_SINK_D2H {1 if dom['can_sink_d2h'] else 0}\n"

    # Liveness info
    liveness = point['liveness_analysis']
    header += f"#define {point_id}_H2D_BYTES {liveness['h2d_total_bytes']}\n"
    header += f"#define {point_id}_D2H_BYTES {liveness['d2h_total_bytes']}\n"
    header += "\n"

# Add compiler hints
header += "// Compiler optimization hints\n"
for point_id, hints in profile.get('compiler_hints', {}).items():
    point_upper = point_id.upper()
    header += f"#define {point_upper}_PREFETCH_DISTANCE {hints.get('prefetch_distance', 64)}\n"
    header += f"#define {point_upper}_THREAD_COARSENING {hints.get('thread_coarsening', 1)}\n"

header += "\n#endif // MCF_OFFLOAD_ANNOTATIONS_H\n"

# Write header
output_path = os.path.join(output_dir, 'mcf_offload_annotations.h')
with open(output_path, 'w') as f:
    f.write(header)

print(f"Generated: {output_path}")

# Print summary
print("\n=== Offload Decisions ===")
for point in profile['offload_points']:
    decision = point['heuristics']['decision']
    symbol = '✓' if 'gpu' in decision else '✗'
    print(f"  {symbol} {point['id']}: {decision}")
    if 'reason' in point['heuristics']:
        print(f"    Reason: {point['heuristics']['reason']}")
EOF

    log_info "  Generated offload annotations header"
}

#==============================================================================
# Step 2: Generate optimized kernel code
#==============================================================================

generate_optimized_kernels() {
    log_step "Step 2: Generating optimized Vortex kernels..."

    # Generate pricing kernel with liveness-based transfers
    cat > "${KERNEL_DIR}/pricing_kernel_optimized.cpp" << 'KERNEL_EOF'
// Optimized MCF Pricing Kernel for Vortex
// Generated with profile-guided liveness analysis

#include <vx_intrinsics.h>
#include <vx_spawn.h>
#include <vx_print.h>

// Arc identifiers
#define BASIC     0
#define AT_LOWER  1
#define AT_UPPER  2

// Kernel arguments - minimal based on liveness analysis
typedef struct {
    // Live-in (H2D)
    int *arc_costs;        // arc->cost
    int *tail_potentials;  // arc->tail->potential
    int *head_potentials;  // arc->head->potential
    int *arc_idents;       // arc->ident
    int num_arcs;
    int group_size;        // NR_GROUP_STATE
    int group_pos;         // GROUP_POS_STATE

    // Live-out (D2H)
    int *red_costs;        // computed reduced costs
    int *is_candidate;     // dual infeasibility flag
    int *candidate_count;  // atomic counter
} pricing_args_t;

// Cycle counter for profiling
#define VX_CSR_MCYCLE 0xB00
inline uint32_t get_cycles() {
    uint32_t cycles;
    asm volatile ("csrr %0, %1" : "=r"(cycles) : "i"(VX_CSR_MCYCLE));
    return cycles;
}

// Kernel: compute reduced costs with strided access pattern
void pricing_kernel_strided(pricing_args_t *__UNIFORM__ args) {
    int tid = vx_thread_id();
    int num_threads = vx_num_threads() * vx_num_warps() * vx_num_cores();

    // Strided access pattern matching original MCF
    for (int idx = args->group_pos + tid * args->group_size;
         idx < args->num_arcs;
         idx += num_threads * args->group_size) {

        // Compute reduced cost
        int red_cost = args->arc_costs[idx]
                     - args->tail_potentials[idx]
                     + args->head_potentials[idx];

        // Store result
        args->red_costs[idx] = red_cost;

        // Check dual infeasibility
        int ident = args->arc_idents[idx];
        int is_cand = ((ident == AT_LOWER && red_cost < 0) ||
                       (ident == AT_UPPER && red_cost > 0)) ? 1 : 0;
        args->is_candidate[idx] = is_cand;

        // Count candidates (reduction)
        if (is_cand) {
            // Simple increment - will be reduced on host
            args->candidate_count[tid]++;
        }
    }
}

// Main test harness
int main() {
    uint32_t start = get_cycles();

    vx_printf("Optimized Pricing Kernel\n");

    // Kernel would be launched by host
    // This is just for testing

    uint32_t end = get_cycles();
    vx_printf("PERF: cycles=%d\n", end - start);

    return 0;
}
KERNEL_EOF

    log_info "  Generated optimized pricing kernel"

    # Build kernel
    if [ -d "${REPO_ROOT}/vortex/tests/kernel/mcf_pricing" ]; then
        log_info "  Building optimized kernel with Vortex SDK..."

        # Copy to Vortex test directory
        cp "${KERNEL_DIR}/pricing_kernel_optimized.cpp" \
           "${REPO_ROOT}/vortex/tests/kernel/mcf_pricing/pricing_optimized.cpp"

        # Build (using existing Makefile)
        # make -C "${REPO_ROOT}/vortex/tests/kernel/mcf_pricing" clean
        # make -C "${REPO_ROOT}/vortex/tests/kernel/mcf_pricing"

        log_info "  Kernel source ready for compilation"
    fi
}

#==============================================================================
# Step 3: Generate host code with H2D/D2H optimizations
#==============================================================================

generate_host_runtime() {
    log_step "Step 3: Generating host runtime with optimized transfers..."

    cat > "${OUTPUT_DIR}/mcf_vortex_runtime.h" << 'RUNTIME_EOF'
// MCF Vortex Runtime - Profile-guided H2D/D2H optimization
// Uses dominator tree analysis for transfer placement

#ifndef MCF_VORTEX_RUNTIME_H
#define MCF_VORTEX_RUNTIME_H

#include <stdint.h>
#include <stdlib.h>

// Include offload annotations
#include "mcf_offload_annotations.h"

// Transfer buffer management
typedef struct {
    void *host_ptr;
    uint64_t device_ptr;
    size_t size;
    int dirty;  // 1 if host has newer data
} transfer_buffer_t;

// Offload context
typedef struct {
    // Device handle
    void *device;

    // Transfer buffers (based on liveness analysis)
    transfer_buffer_t arc_costs;
    transfer_buffer_t tail_potentials;
    transfer_buffer_t head_potentials;
    transfer_buffer_t arc_idents;
    transfer_buffer_t red_costs;
    transfer_buffer_t is_candidate;

    // Timing
    uint64_t h2d_cycles;
    uint64_t d2h_cycles;
    uint64_t kernel_cycles;

    // Stats
    int h2d_count;
    int d2h_count;
    int kernel_invocations;
} offload_context_t;

// Initialize offload context
int offload_init(offload_context_t *ctx, int num_arcs);

// Cleanup
void offload_cleanup(offload_context_t *ctx);

// H2D transfer with hoisting optimization
// Only transfers if data changed since last transfer
int offload_h2d(offload_context_t *ctx,
                int *arc_costs, int *tail_pot, int *head_pot, int *idents,
                int num_arcs, int force);

// D2H transfer with sinking optimization
// Defers transfer until data is actually needed
int offload_d2h(offload_context_t *ctx,
                int *red_costs, int *is_candidate,
                int num_arcs);

// Launch pricing kernel
// Conditional offload based on element count
int offload_pricing_kernel(offload_context_t *ctx,
                          int num_arcs,
                          int group_size,
                          int group_pos,
                          int *candidate_count);

// Check if offload is beneficial based on profile
static inline int should_offload_pricing(int num_arcs) {
#if OFFLOAD_PRICING_KERNEL == 0
    return 0;  // CPU only
#elif OFFLOAD_PRICING_KERNEL == 1
    return 1;  // Always offload
#else
    return num_arcs >= PRICING_KERNEL_MIN_ELEMENTS;  // Conditional
#endif
}

// Get profiling stats
void offload_get_stats(offload_context_t *ctx,
                      uint64_t *h2d_ns, uint64_t *d2h_ns, uint64_t *kernel_ns);

#endif // MCF_VORTEX_RUNTIME_H
RUNTIME_EOF

    log_info "  Generated host runtime header"
}

#==============================================================================
# Step 4: Print compilation instructions
#==============================================================================

print_compilation_instructions() {
    log_step "Step 4: Compilation Instructions"

    log_info ""
    log_info "=== Generated Files ==="
    log_info "  ${OUTPUT_DIR}/mcf_offload_annotations.h"
    log_info "  ${OUTPUT_DIR}/mcf_vortex_runtime.h"
    log_info "  ${KERNEL_DIR}/pricing_kernel_optimized.cpp"
    log_info ""
    log_info "=== Offload Decision Summary ==="

    # Parse and display decisions
    python3 << EOF
import json

with open("${PER_POINT_PROFILE}", 'r') as f:
    profile = json.load(f)

print("  Offload Point          | Decision           | Min Elements | Speedup")
print("  " + "-" * 70)

for point in profile['offload_points']:
    name = point['id']
    decision = point['heuristics']['decision']
    min_elem = point['heuristics'].get('crossover_point_elements', 'N/A')
    speedup = point['heuristics'].get('speedup_at_64_elements',
              point['heuristics'].get('speedup_at_1000_elements',
              point['heuristics'].get('speedup_at_50_elements', 'N/A')))

    if isinstance(speedup, (int, float)):
        speedup = f"{speedup:.2f}x"

    print(f"  {name:<22} | {decision:<18} | {str(min_elem):<12} | {speedup}")
EOF

    log_info ""
    log_info "=== To Build Heterogeneous MCF ==="
    log_info ""
    log_info "1. Add to MCF compilation:"
    log_info "   -I${OUTPUT_DIR} -DMCF_VORTEX_OFFLOAD"
    log_info ""
    log_info "2. Modify pbeampp.c to use offload runtime:"
    log_info "   #include \"mcf_offload_annotations.h\""
    log_info "   #include \"mcf_vortex_runtime.h\""
    log_info ""
    log_info "3. Replace pricing loop with:"
    log_info "   if (should_offload_pricing(num_arcs)) {"
    log_info "       offload_pricing_kernel(&ctx, num_arcs, ...);"
    log_info "   } else {"
    log_info "       // Original CPU code"
    log_info "   }"
    log_info ""
    log_info "4. Build Vortex kernel:"
    log_info "   cd ${REPO_ROOT}/vortex/tests/kernel/mcf_pricing && make"
    log_info ""
}

#==============================================================================
# Main
#==============================================================================

main() {
    log_info "=== MCF Heterogeneous Compilation with Profile-Guided Optimization ==="
    log_info ""
    log_info "Using profiles:"
    log_info "  Per-point: ${PER_POINT_PROFILE}"
    log_info "  Compiler:  ${COMPILER_PROFILE}"
    log_info ""

    # Export paths for Python scripts
    export PER_POINT_PROFILE
    export OUTPUT_DIR
    export KERNEL_DIR

    generate_offload_annotations
    generate_optimized_kernels
    generate_host_runtime
    print_compilation_instructions

    log_info ""
    log_info "Heterogeneous compilation setup complete!"
    log_info "Output directory: ${OUTPUT_DIR}"
}

main "$@"
